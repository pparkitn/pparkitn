{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca50ac",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell For Papermill Parameters\n",
    "\"\"\"\n",
    "\n",
    "ARCH = 'resnet18'\n",
    "NUM_CLASSES = 2\n",
    "EPOCHS = 50\n",
    "START_EPOCH = 0\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 10\n",
    "TRAIN_BATCH= 22\n",
    "imagesize = 400\n",
    "WORKERS=4\n",
    "LR_EPOCH_DROP = 1000\n",
    "TRAINDIR=\"../../dataset/ds1/train\"\n",
    "VALDIR=\"../../dataset/ds1/test\"\n",
    "wb_project = \"DNN-Model\"\n",
    "model_save_file = \"model_MRI.pth.tar\"\n",
    "cosine_hoops = 2\n",
    "nn_lock_ly = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4706a993",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import torch.distributed as dist\n",
    "\n",
    "import wandb\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "from timm.scheduler.step_lr import StepLRScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911eb03",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7ff58",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "GPU=0\n",
    "\n",
    "SEED=1\n",
    "VAL_BATCH=TRAIN_BATCH\n",
    "\n",
    "phone=\"\"\n",
    "\n",
    "with open('../config/config.json') as config_f:\n",
    "  data = json.load(config_f)\n",
    "aws_access_key_id = data['aws_access_key_id']\n",
    "aws_secret_access_key = data['aws_secret_access_key']\n",
    "region_name = data['region_name']\n",
    "WANDB_API_KEY = data['WANDB_API_KEY']\n",
    "\n",
    "classes_train = os.listdir(TRAINDIR)\n",
    "classes_valid = os.listdir(VALDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac94655",
   "metadata": {},
   "source": [
    "# Weights & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a875330",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "wandb.login()\n",
    "run = wandb.init(project=wb_project, entity='prostate-cancer', config={\"epochs\": EPOCHS, \"batch_size\": TRAIN_BATCH, \"momentum\": MOMENTUM, \n",
    "                   \"WEIGHT_DECAY\": WEIGHT_DECAY, \"arch\": ARCH, \"TRAINDIR\":TRAINDIR,\"VALDIR\":VALDIR,\n",
    "                  \"imagesize\":imagesize, \"NUM_CLASSES\":NUM_CLASSES,\"classes_train\":classes_train,\"classes_valid\":classes_valid})\n",
    "\n",
    "wandb_run_name = wandb.run.name\n",
    "wandb_run_id = wandb.run.id\n",
    "\n",
    "config = wandb.config\n",
    "config.learning_rate = LR\n",
    "config.LR_EPOCH_DROP = LR_EPOCH_DROP\n",
    "config.cosine_hoops = cosine_hoops\n",
    "config.nn_lock_ly = nn_lock_ly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7a54a9",
   "metadata": {},
   "source": [
    "# Review Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db5f78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_folder in classes_train:\n",
    "    print(\"==================================\")\n",
    "    class_folder = class_folder +'/'\n",
    "    full_path = os.path.join(TRAINDIR, class_folder)\n",
    "    print(full_path)\n",
    "    fileList = glob.glob(full_path +'*jpg*', recursive=True)\n",
    "    print(len(fileList))\n",
    "\n",
    "for class_folder in classes_valid:\n",
    "    print(\"==================================\")\n",
    "    class_folder = class_folder +'/'\n",
    "    full_path = os.path.join(VALDIR, class_folder)\n",
    "    print(full_path)\n",
    "    fileList = glob.glob(full_path +'*jpg*', recursive=True)\n",
    "    print(len(fileList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac956587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_sms(phone,text,aws_access_key_id,aws_secret_access_key,region_name):\n",
    "    # Create an SNS client\n",
    "    client = boto3.client(\n",
    "        \"sns\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # Send sms message.\n",
    "    client.publish(\n",
    "        PhoneNumber=phone,\n",
    "        Message=text\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132695cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_aws(local_file, bucket, s3_file,aws_access_key_id,aws_secret_access_key):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id,\n",
    "                      aws_secret_access_key=aws_secret_access_key)\n",
    "    try:\n",
    "        s3.upload_file(local_file, bucket, s3_file)\n",
    "        print(\"Upload Successful\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found\")\n",
    "        return False\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False\n",
    "\n",
    "def download_from_aws(s3_file, bucket,aws_access_key_id,aws_secret_access_key):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id,\n",
    "                      aws_secret_access_key=aws_secret_access_key)\n",
    "    try:\n",
    "        s3.download_file(bucket, s3_file, s3_file)\n",
    "        print(\"Download Successful\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found\")\n",
    "        return False\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b85ee6",
   "metadata": {
    "id": "4e65743f"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # Grad Scaler\n",
    "    scaler = GradScaler()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with autocast():\n",
    "          output = model(images)\n",
    "          loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 2))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7fea2",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 2))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b2df1",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename_in):\n",
    "    torch.save(state, filename_in)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename_in, 'model_best_'+wb_project+'_'+wandb_run_name+'_'+str(imagesize)+'.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41877be",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033e209",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5bd95",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // LR_EPOCH_DROP))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38035af",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8b610",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b13ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0cff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05036987",
   "metadata": {
    "id": "acd97390"
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(GPU)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "model = models.__dict__[ARCH](pretrained = True)\n",
    "inf = model.fc.in_features\n",
    "model.fc = nn.Linear(inf, NUM_CLASSES)\n",
    "\n",
    "ml = model.cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This freezes layers 1-3 in the total 10 layers of Resnet50\n",
    "ct = 0\n",
    "for child in model.children():\n",
    "    ct += 1\n",
    "    print(child)\n",
    "    print(ct)\n",
    "    if ct < nn_lock_ly:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ac4d7",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dbec92",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr = LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "cosine_restart = EPOCHS/cosine_hoops\n",
    "cosine_restart = int(cosine_restart - (cosine_restart/(cosine_hoops*2)))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cosine_restart,eta_min = 0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((imagesize,imagesize)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056bbc0",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((imagesize,imagesize)),\n",
    "    transforms.ToTensor(),    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c0723",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(TRAINDIR, transform=transform_train)\n",
    "val_dataset = datasets.ImageFolder(VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c37e5",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=TRAIN_BATCH, shuffle=True,num_workers=WORKERS, pin_memory=True, sampler=None)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=VAL_BATCH, shuffle=False,num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22dcb6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef3e2ff",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "best_acc1 = 0\n",
    "lrls = []\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    \n",
    "    #adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    PATH = \"E\" +str(epoch) + \"_acc1_\" +str(round(acc1.item(),2)) + \"_\" + wandb_run_name + \".tar\" \n",
    "        \n",
    "    #save_checkpoint({'epoch': epoch + 1,'arch': ARCH,'state_dict': model.state_dict(),'best_acc1': best_acc1,'optimizer' : optimizer.state_dict(),}, is_best,PATH)    \n",
    "    #upload_to_aws(PATH, 'prostate-cancer', PATH,aws_access_key_id,aws_secret_access_key)\n",
    "\n",
    "    lrls.append(scheduler.get_last_lr()[0])      \n",
    "    lr_float = float(scheduler.get_last_lr()[0])\n",
    "    scheduler.step()\n",
    "    \n",
    "    wandb.log({'lr':lr_float, 'epoch':epoch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df60e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.Series(lrls).plot(logy=True, figsize = (15, 6), title=\"Learning Rate VS Epoch\")\n",
    "for i in range(0,EPOCHS,1): \n",
    "    ax.axvline(i, linewidth=0.01, color='r', linestyle='--')\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"LR (log scale)\")\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('LR_graph-log.png')\n",
    "wandb.log({\"Media/LR-Graph-Log\": wandb.Image(\"LR_graph-log.png\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e65d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 2),frameon =False, dpi=200)  \n",
    "plt.title('Learning Rate VS Epoch')\n",
    "plt.plot(lrls)\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Epoch')\n",
    "fn = \"LR_graph.png\"\n",
    "plt.savefig(fn,bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "wandb.log({\"Media/LR-Graph\": wandb.Image(\"LR_graph.png\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = model_save_file\n",
    "save_checkpoint({'epoch': epoch + 1,'arch': ARCH,'state_dict': model.state_dict(),'best_acc1': best_acc1,'optimizer' : optimizer.state_dict(),}, is_best,PATH)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ffbb34",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccf6c6b",
   "metadata": {},
   "source": [
    "## Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "saved_model_name = PATH\n",
    "data_dir=VALDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf383b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(GPU)\n",
    "\n",
    "model = models.__dict__[ARCH](pretrained = True)\n",
    "inf = model.fc.in_features\n",
    "model.fc = nn.Linear(inf, NUM_CLASSES)\n",
    "model.cuda(GPU)\n",
    "\n",
    "loc = 'cuda:{}'.format(GPU)\n",
    "checkpoint = torch.load(saved_model_name, map_location=loc)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35777f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transform_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd4ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        image_tensor = test_transforms(image).float()\n",
    "        image_tensor = image_tensor.unsqueeze_(0)\n",
    "        input = Variable(image_tensor)\n",
    "        input = input.to(device)\n",
    "        output = model(input)\n",
    "        index = output.data.cpu().numpy().argmax()\n",
    "       \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35447e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_images(num,transforms):\n",
    "    \n",
    "    data = datasets.ImageFolder(data_dir, transform=transforms)\n",
    "    classes = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "    \n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf2391",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, classes = get_random_images(10,transform_val)\n",
    "wandb.log({\"examples-val\": [wandb.Image(image) for image in images]})\n",
    "\n",
    "images, labels, classes = get_random_images(10,transform_train)\n",
    "wandb.log({\"examples-train\": [wandb.Image(image) for image in images]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa1f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "while counter < 4:\n",
    "    to_pil = transforms.ToPILImage()\n",
    "    images, labels, classes = get_random_images(5,test_transforms)\n",
    "    fig=plt.figure(figsize=(30,30))\n",
    "    \n",
    "    for ii in range(len(images)):\n",
    "        image = to_pil(images[ii])        \n",
    "        index = predict_image(image)\n",
    "        sub = fig.add_subplot(1, len(images), ii+1)\n",
    "        res = int(labels[ii])\n",
    "        label_class = int(labels[ii])\n",
    "        sub.set_title(str(classes[index]) + \":\" + classes[label_class])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "    plt.savefig(\"sample.png\")\n",
    "    plt.show()\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7024ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "while counter < 4:\n",
    "    to_pil = transforms.ToPILImage()\n",
    "    images, labels, classes = get_random_images(5,transform_train)\n",
    "    fig=plt.figure(figsize=(30,30))\n",
    "    \n",
    "    #wandb.log({\"examples\": [wandb.Image(image) for image in images]})\n",
    "    \n",
    "    for ii in range(len(images)):\n",
    "        image = to_pil(images[ii])        \n",
    "        index = predict_image(image)\n",
    "        sub = fig.add_subplot(1, len(images), ii+1)\n",
    "        res = int(labels[ii])\n",
    "        label_class = int(labels[ii])\n",
    "        sub.set_title(str(classes[index]) + \":\" + classes[label_class])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "    plt.savefig(\"sample.png\")\n",
    "    plt.show()\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01641856",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = []\n",
    "predicted = []\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "images, labels, classes = get_random_images(500,transform_val)\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    index = predict_image(image)\n",
    "    res = int(labels[ii])\n",
    "    label_class = int(labels[ii])\n",
    "    actual.append(classes[label_class])\n",
    "    predicted.append(str(classes[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c99f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892046eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE https://runawayhorse001.github.io/LearningApacheSpark/classification.html\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig = plt.figure(figsize=(3, 3),frameon =False, dpi=200)  \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c4fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "class_names = classes\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,title='Confusion matrix')\n",
    "plt.savefig(\"confusion-matrix.png\",bbox_inches='tight')\n",
    "wandb.log({\"Media/Confusion Matrix\": wandb.Image(\"confusion-matrix.png\")})\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,title='Normalized confusion matrix')\n",
    "plt.savefig(\"confusion-matrix-normalized.png\",bbox_inches='tight')\n",
    "wandb.log({\"Media/Normalized Confusion Matrix\": wandb.Image(\"confusion-matrix-normalized.png\")})\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(actual, predicted, target_names=class_names))\n",
    "print(accuracy_score(actual, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8005815",
   "metadata": {},
   "source": [
    "# ROC Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88765ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ROC_graph(labels_test,prediction):\n",
    "    \"\"\" Text \"\"\"\n",
    "\n",
    "    false_positive_rate, recall, thresholds = roc_curve(labels_test,prediction)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    fig = plt.figure(figsize=(3, 3),frameon =False, dpi=200)  \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' %roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    fn = \"roc_graph.png\"\n",
    "    plt.savefig(fn,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    wandb.log({\"Media/ROC-Graph\": wandb.Image(\"roc_graph.png\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc198cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_b = []\n",
    "predicted_b = []\n",
    "\n",
    "for x in actual:\n",
    "    if x == 'pos':\n",
    "        actual_b.append(1)\n",
    "    else:\n",
    "        actual_b.append(0)\n",
    "\n",
    "for x in predicted:\n",
    "    if x == 'pos':\n",
    "        predicted_b.append(1)\n",
    "    else:\n",
    "        predicted_b.append(0)\n",
    "                \n",
    "make_ROC_graph(actual_b,predicted_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33891a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the run as finished\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfc9a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_text = wandb_run_name + \" Is Complete\"\n",
    "send_sms(phone,sms_text,aws_access_key_id,aws_secret_access_key,region_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
