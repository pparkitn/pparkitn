{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell For Papermill Parameters\n",
    "\"\"\"\n",
    "\n",
    "ARCH = 'resnet18'\n",
    "imagesize = 100\n",
    "NUM_CLASSES = 2\n",
    "saved_model_name = \"model_MRI.pth.tar\"\n",
    "data_dir=\"../../dataset/ds1/val/\"\n",
    "out_file = \"uncertainty_MRI.csv\"\n",
    "wb_project = \"Uncertainty_MRI\"\n",
    "WORKERS=4\n",
    "GPU=0\n",
    "SEED=1\n",
    "VAL_BATCH = 6\n",
    "forward_passes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import gc\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/config.json') as config_f:\n",
    "    data = json.load(config_f)\n",
    "aws_access_key_id = data['aws_access_key_id']\n",
    "aws_secret_access_key = data['aws_secret_access_key']\n",
    "region_name = data['region_name']\n",
    "WANDB_API_KEY = data['WANDB_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "wandb.login()\n",
    "run = wandb.init(project=wb_project, entity='prostate-cancer', config={\"imagesize\":imagesize, \"NUM_CLASSES\":NUM_CLASSES})\n",
    "\n",
    "wandb_run_name = wandb.run.name\n",
    "wandb_run_id = wandb.run.id\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "config.ARCH  = ARCH \n",
    "config.imagesize  = imagesize \n",
    "config.forward_passes = forward_passes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Declare Functions Used for DNN Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_dropout(model):\n",
    "    \"\"\" Function to enable the dropout layers during test-time \"\"\"\n",
    "    for m in model.modules():\n",
    "        m.register_forward_hook(lambda m, inp, out: F.dropout(out, p=0.1, training=True))\n",
    "                  \n",
    "def get_model_monte_carlo_predictions(data_loader, forward_passes,\n",
    "                                      model, n_classes, n_samples):\n",
    "    \"\"\" Function to get the model monte-carlo samples and uncertainty estimates\n",
    "    through multiple forward passes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_loader : object\n",
    "        data loader object from the data loader module\n",
    "    forward_passes : int\n",
    "        number of monte-carlo samples/forward passes\n",
    "    model : object\n",
    "        keras model\n",
    "    n_classes : int\n",
    "        number of classes in the dataset\n",
    "    n_samples : int\n",
    "        number of samples in the test set\n",
    "    \"\"\"\n",
    "\n",
    "    dropout_predictions = np.empty((0, n_samples, n_classes))\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    model.eval()\n",
    "    enable_dropout(model)\n",
    "    \n",
    "    for i in range(forward_passes):\n",
    "        \n",
    "        # counter\n",
    "        if (((i+1) % 50) == 0) and ((i+1) >= 50):\n",
    "            print(\"Number of passes finished:\")\n",
    "            print(i+1)\n",
    "        \n",
    "        predictions = np.empty((0, n_classes))\n",
    "\n",
    "        for i, (image, label) in enumerate(data_loader):\n",
    "\n",
    "            image = image.to(torch.device('cuda'))\n",
    "            with torch.no_grad():\n",
    "                output = model(image)\n",
    "                output = softmax(output) # shape (n_samples, n_classes)\n",
    "            predictions = np.vstack((predictions, output.cpu().numpy()))\n",
    "\n",
    "        dropout_predictions = np.vstack((dropout_predictions,\n",
    "                                         predictions[np.newaxis, :, :]))\n",
    "        # dropout predictions - shape (forward_passes, n_samples, n_classes)\n",
    "    \n",
    "    # Calculating mean across multiple MCD forward passes \n",
    "    mean = np.mean(dropout_predictions, axis=0) # shape (n_samples, n_classes)\n",
    "\n",
    "    # Calculating variance across multiple MCD forward passes \n",
    "    variance = np.var(dropout_predictions, axis=0) # shape (n_samples, n_classes)\n",
    "    \n",
    "    return tuple([mean, (variance**0.5)])\n",
    "\n",
    "def get_input_monte_carlo_predictions(data_loader, forward_passes,\n",
    "                                      model, n_classes, n_samples,\n",
    "                                     num_channels, image_size):\n",
    "    \"\"\" Function to get the monte-carlo samples and uncertainty estimates\n",
    "    through multiple forward passes\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_loader : object\n",
    "        data loader object from the data loader module\n",
    "    forward_passes : int\n",
    "        number of monte-carlo samples/forward passes\n",
    "    model : object\n",
    "        keras model\n",
    "    n_classes : int\n",
    "        number of classes in the dataset\n",
    "    n_samples : int\n",
    "        number of samples in the test set\n",
    "    num_channels : int\n",
    "        number of channels in the image\n",
    "    image_size : int\n",
    "        size of image in pixels, assuming a square image\n",
    "    \"\"\"\n",
    "    \n",
    "    noise_predictions = np.empty((0, n_samples, n_classes))\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    # create forward_passes number of monte carlo predictions for each unique image\n",
    "    for i in range(forward_passes):\n",
    "        \n",
    "        # counter\n",
    "        if (((i+1) % 50) == 0) and ((i+1) >= 50):\n",
    "            print(\"Number of passes finished:\")\n",
    "            print(i+1)\n",
    "        \n",
    "        predictions = np.empty((0, n_classes))\n",
    "        model.eval()\n",
    "\n",
    "        for i, (image, label) in enumerate(data_loader):\n",
    "            \n",
    "            # adjust batchsize because the final loop may be less\n",
    "            # than a full batch\n",
    "            current_batchsize = image.shape[0]\n",
    "            \n",
    "            noise = torch.normal(mean = 0., std = 1., size = [current_batchsize, num_channels, \n",
    "                                                              image_size, image_size])\n",
    "\n",
    "            noisy_image = image + noise\n",
    "\n",
    "            # send images to gpu\n",
    "            noisy_image = noisy_image.to(torch.device('cuda'))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(noisy_image)\n",
    "                output = softmax(output) # shape (n_samples, n_classes)\n",
    "            predictions = np.vstack((predictions, output.cpu().numpy()))\n",
    "\n",
    "\n",
    "        noise_predictions = np.vstack((noise_predictions,\n",
    "                                         predictions[np.newaxis, :, :]))\n",
    "        # noise predictions - shape (forward_passes, n_samples, n_classes)\n",
    "    \n",
    "    # Calculating mean across multiple forward passes \n",
    "    mean = np.mean(noise_predictions, axis=0) # shape (n_samples, n_classes)\n",
    "\n",
    "    # Calculating variance across multiple forward passes \n",
    "    variance = np.var(noise_predictions, axis=0) # shape (n_samples, n_classes)\n",
    "    \n",
    "    return tuple([mean, (variance**0.5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Load DNN Model + Make Predictions / Uncertainty Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Load DNN MRI Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Load DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True\n",
    "\n",
    "torch.cuda.set_device(GPU)\n",
    "\n",
    "model = models.__dict__[ARCH](pretrained = True)\n",
    "inf = model.fc.in_features\n",
    "model.fc = nn.Linear(inf, NUM_CLASSES)\n",
    "model.cuda(GPU)\n",
    "\n",
    "loc = 'cuda:{}'.format(GPU)\n",
    "checkpoint = torch.load(saved_model_name, map_location=loc)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Make Uncertainty Estimates on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new section to prep uncertainty estimates ##\n",
    "\n",
    "transform_mri = transforms.Compose([\n",
    "    transforms.Resize((imagesize,imagesize)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mri_dataset = datasets.ImageFolder(\n",
    "    data_dir, transform=transform_mri)\n",
    "\n",
    "# Make sure shuffle = False so that each monte carlo loop\n",
    "# evaluates the same image at the same index\n",
    "mri_loader = torch.utils.data.DataLoader(\n",
    "        mri_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new section to make input uncertainty estimates ## \n",
    "## make sure to run this section before and never after the model\n",
    "## uncertainty, because model uncertainty adds dropout layers that \n",
    "## are permanently on\n",
    "\n",
    "mri_predictions_input = get_input_monte_carlo_predictions(\n",
    "    mri_loader, forward_passes = forward_passes,\n",
    "    model = model, n_classes = NUM_CLASSES, n_samples = len(mri_dataset),\n",
    "    num_channels = 3, image_size = imagesize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new section to make model uncertainty estimates ##\n",
    "\n",
    "mri_predictions_model = get_model_monte_carlo_predictions(\n",
    "    mri_loader, forward_passes = forward_passes,\n",
    "    model = model, n_classes = NUM_CLASSES, n_samples = len(mri_dataset)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## new section to process uncertainty estimates ##\n",
    "\n",
    "# This object is a list to hold output uncertainties that come from the input data.\n",
    "#\n",
    "# mri_predictions_input is a tuple with both the mean predicted probabilities and \n",
    "# estimated uncertainties for all samples over each potential label. See function above.\n",
    "#\n",
    "# mri_predictions_input[0] accesses the means, mri_predictions_input[1] accesses the uncertainties\n",
    "# mri_predictions_input[1][i] accesses uncertainties for the the i-th example over each output class / label\n",
    "#\n",
    "# Because this is binary classification, uncertainty in one label is equal to the uncertainty in the other. \n",
    "# i.e. mri_predictions_input[1][i][0] = mri_predictions_input[1][i][1], so only one is needed\n",
    "mri_input_uncertainties = [mri_predictions_input[1][i][0] for i in range(len(mri_predictions_input[1]))]\n",
    "\n",
    "# list to hold output uncertainties that come from the model\n",
    "mri_model_uncertainties = [mri_predictions_model[1][i][0] for i in range(len(mri_predictions_model[1]))]\n",
    "\n",
    "# calculate the combined uncertainty, which is just the sqrt of the sum of squares of each contribution\n",
    "mri_combined_uncertainties = [((input_unc**2) + (model_unc**2))**0.5\n",
    "                              for input_unc, model_unc \n",
    "                              in zip(mri_input_uncertainties,mri_model_uncertainties)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mri_combined_uncertainties)\n",
    "df.to_csv(out_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_file+'.pickle', 'wb') as f:\n",
    "    pickle.dump(mri_combined_uncertainties, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_combined_uncertainties[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_input_uncertainties[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_model_uncertainties[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
