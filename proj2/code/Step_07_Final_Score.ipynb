{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86038013",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell For Papermill Parameters\n",
    "\"\"\"\n",
    "\n",
    "test_size = 0.2\n",
    "input_data = \"to_ngboost.csv\"\n",
    "Label_Column = 'label_clas'\n",
    "wandb_log = 0\n",
    "estimators = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef739d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import wandb\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99aee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1)\n",
    "sns.set_style(\"white\")\n",
    "sns.set_palette(\"rocket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41733c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOURCE https://runawayhorse001.github.io/LearningApacheSpark/classification.html\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig = plt.figure(figsize=(3, 3),frameon =False, dpi=200)  \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de881536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ROC_graph(labels_test,prediction):\n",
    "    \"\"\" Text \"\"\"\n",
    "\n",
    "    false_positive_rate, recall, thresholds = roc_curve(labels_test,prediction)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    fig = plt.figure(figsize=(3, 3),frameon =False, dpi=200)  \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positive_rate, recall, 'b', label='AUC = %0.2f' %roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    fn = \"roc_graph.png\"\n",
    "    plt.savefig(fn,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ac1506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_precision_recall_graph(labels_test,prediction):\n",
    "    \"\"\" Text \"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(labels_test, prediction)\n",
    "    average_precision = average_precision_score(labels_test, prediction)\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(3, 3),frameon =False, dpi=200)  \n",
    "    plt.plot(recall, precision, color='navy', label='Precision-Recall curve')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve | Area ='+str(round(average_precision,2)))\n",
    "    fn = \"precision_recall.png\"\n",
    "    plt.savefig(fn,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18200d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_importance_graph(df):\n",
    "    \"\"\" Text \"\"\"\n",
    "    plt.clf()\n",
    "    fig = plt.figure(figsize=(5, 3),frameon =False, dpi=200)  \n",
    "    fig = sns.barplot(y=\"Feature_Name\", x=\"Importance\", data=importances_df_final)\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importance')\n",
    "    fn = \"importance.png\"\n",
    "    plt.savefig(fn,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/config.json') as config_f:\n",
    "  data = json.load(config_f)\n",
    "aws_access_key_id = data['aws_access_key_id']\n",
    "aws_secret_access_key = data['aws_secret_access_key']\n",
    "region_name = data['region_name']\n",
    "WANDB_API_KEY = data['WANDB_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b3e587",
   "metadata": {},
   "outputs": [],
   "source": [
    "if wandb_log == 1:\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "    wandb.login()\n",
    "    run = wandb.init(project=\"Final-Model\", entity='prostate-cancer', config={\"test_size\":test_size})\n",
    "    wandb_run_name = wandb.run.name\n",
    "    wandb_run_id = wandb.run.id\n",
    "    config = wandb.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7687a04e",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19878978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_data)\n",
    "\n",
    "#df.drop([\"cancer_in_core_max\",\"cancer_in_core_mean\",\"patient\",\"Patient Number\",\"name\",\"ethnic_grp\",\"occupation\",\"patient_US\"],axis=1, inplace=True)\n",
    "df.drop([\"name\",\"smoking_status\",\"occupation\",\"Model-MRI-DNN\",\"Model-US-DNN\"],axis=1, inplace=True)\n",
    "\n",
    "age_mean = df[\"age\"].mean()\n",
    "size_mean = df[\"size\"].mean()\n",
    "weight_mean = df[\"weight\"].mean()\n",
    "psa_mean = df[\"PSA\"].mean()\n",
    "\n",
    "df= df.fillna({\"age\":age_mean, \"size\":size_mean, \"weight\":weight_mean, \"PSA\":psa_mean})\n",
    "df.to_csv(\"final_result.csv\", sep=',', encoding='utf-8', index=False)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.loc[df.ethnic_grp ==\"Patient Refused\",\"ethnic_grp\"] = \"Unknown\"\n",
    "df.loc[df.ethnic_grp ==\"Unknown [3]\",\"ethnic_grp\"] = \"Unknown\"\n",
    "\n",
    "Label_Column = 'label_clas'\n",
    "df[Label_Column] = df[Label_Column].astype(int)\n",
    "\n",
    "features_df = df.drop(Label_Column,axis=1,inplace=False)\n",
    "features_one_hot_df = pd.get_dummies(features_df)\n",
    "\n",
    "labels_df = df[[Label_Column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc9173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_one_hot_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59486688",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_np = features_one_hot_df.values.tolist()\n",
    "labels_np = labels_df.values.ravel()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features_np,labels_np, random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ce52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=estimators,n_jobs=-1,verbose=0)\n",
    "clf = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd52537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e3079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(clf, X_test, Y_test)\n",
    "cnf_matrix = confusion_matrix(Y_test,prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0843e",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f057ed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['neg','pos']\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "class_names = classes\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,title='Confusion matrix')\n",
    "plt.savefig(\"confusion-matrix.png\")\n",
    "if wandb_log == 1:\n",
    "    wandb.log({\"Media/Confusion Matrix\": wandb.Image(\"confusion-matrix.png\")})\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,title='Normalized confusion matrix')\n",
    "plt.savefig(\"confusion-matrix-normalized.png\")\n",
    "if wandb_log == 1:\n",
    "    wandb.log({\"Media/Normalized Confusion Matrix\": wandb.Image(\"confusion-matrix-normalized.png\")})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed23582",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, prediction, target_names=classes))\n",
    "print(accuracy_score(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa05061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ROC_graph(Y_test, prediction)\n",
    "plt.show()\n",
    "plt.close()\n",
    "if wandb_log == 1:\n",
    "    wandb.log({\"Media/ROC-Graph-RF\": wandb.Image(\"roc_graph.png\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa68a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_precision_recall_graph(Y_test,prediction)\n",
    "plt.show()\n",
    "plt.close()\n",
    "if wandb_log == 1:\n",
    "    wandb.log({\"Media/Precision_Recall\": wandb.Image(\"precision_recall.png\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70072420",
   "metadata": {},
   "source": [
    "# Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea04fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "importances_df = pd.DataFrame(importances)\n",
    "column_names_df  = pd.DataFrame(features_one_hot_df.columns.values.tolist())\n",
    "importances_df_final = pd.merge(column_names_df,importances_df, left_index=True,right_index=True)\n",
    "importances_df_final.columns = [\"Feature_Name\", \"Importance\"]\n",
    "importances_df_final = importances_df_final.sort_values(by=['Importance'], ascending=False)\n",
    "imp_list = [importances_df_final.columns.values.tolist()] + importances_df_final.values.tolist()\n",
    "importances_df_final.to_csv('imp_features.csv', index=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8d0b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_importance_graph(importances_df_final)\n",
    "plt.show()\n",
    "plt.close()\n",
    "if wandb_log == 1:\n",
    "    wandb.log({\"Media/Importance\": wandb.Image(\"importance.png\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae0d66f",
   "metadata": {},
   "source": [
    "# Prediction Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccacc09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test)\n",
    "probability = clf.predict_proba(X_test)\n",
    "\n",
    "probability_df = pd.DataFrame(probability)\n",
    "probability_df.columns = ['Prob_0','Prob_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b05cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the run as finished\n",
    "if wandb_log == 1:\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
