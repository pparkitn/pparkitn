{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19e81bcf-ed66-4ba8-a26f-0dde5a1041a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import glob, os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39051436-07d1-4a7d-8a91-e7d685ab78dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## initialize pose estimator\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98bffd1a-38e3-4af9-bdc0-3c798b6cbbc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['video_source\\\\IMG_8839.MOV',\n",
       " 'video_source\\\\IMG_8840.MOV',\n",
       " 'video_source\\\\IMG_8842.MOV',\n",
       " 'video_source\\\\IMG_8843.MOV',\n",
       " 'video_source\\\\IMG_8844.MOV',\n",
       " 'video_source\\\\IMG_8845.MOV',\n",
       " 'video_source\\\\IMG_8846.MOV',\n",
       " 'video_source\\\\IMG_8848.MOV']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileList = glob.glob('video_source/*' , recursive=True)\n",
    "fileList.sort()\n",
    "fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3aa94cc1-df2e-4f14-95fb-9c304a677f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ffmpeg_path = \"../../../ffmpeg/bin/ffmpeg.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85bebbb-f66c-43ab-a0e5-47e3c88e2355",
   "metadata": {},
   "source": [
    "# TRIM SECONDS FROM BEG OF VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d13bef91-46f8-4943-9cfa-f78141b0649c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trim_video_from_beg(ffmpeg_path,input_video,output_video,shortened_duration):    \n",
    " \n",
    "    command = [ffmpeg_path, '-i', input_video, '-ss', str(shortened_duration), \"-c\", \"copy\", output_video]\n",
    "\n",
    "    try:\n",
    "        # Run the command\n",
    "        subprocess.run(command, check=True)\n",
    "        print(f\"Video shortened successfully to {shortened_duration} seconds.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b5b29-3580-45b3-9a8a-062b22f900a7",
   "metadata": {},
   "source": [
    "# MERGE TWO VIDEOES SIDE BY SIDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c3e2816-7bef-4ebe-946b-5e2e284c4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_two_videos_sbys(ffmpeg_path,input_video1,input_video2,output_video):\n",
    "    # Get the number of CPU cores\n",
    "    cpu_cores = os.cpu_count()\n",
    "    \n",
    "    # Example command to combine videos side by side with all CPUs\n",
    "    command = [\n",
    "        ffmpeg_path,\n",
    "        '-i', input_video1,\n",
    "        '-i', input_video2,\n",
    "        '-filter_complex', f'[0:v]pad=iw*2:ih[int];[int][1:v]overlay=W/2:0[vid]',\n",
    "        '-map', '[vid]',\n",
    "        '-threads', str(cpu_cores),  # Use all available CPU cores\n",
    "        output_video\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        # Run the command\n",
    "        subprocess.run(command, check=True)\n",
    "        print(\"Videos combined side by side successfully using all CPUs.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4feba8-f581-4706-8810-0481b86f108c",
   "metadata": {},
   "source": [
    "# MAKE GIF FROM VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "152c64f2-da10-4feb-b547-0de0aab4c3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_gif(input_video,output_gif):\n",
    "\n",
    "    # Example command to convert video to animated GIF\n",
    "    command = [ffmpeg_path, '-i', input_video, '-vf', 'fps=10,scale=640:-1', '-c:v', 'gif', output_gif]\n",
    "\n",
    "    try:\n",
    "        # Run the command\n",
    "        subprocess.run(command, check=True)\n",
    "        print(\"Video converted to animated GIF successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f74fdf9-fedd-49bb-90c4-f5a9a5d082ce",
   "metadata": {},
   "source": [
    "# ADD MOTION TRACK TO VIDEO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8eead0e4-0ca2-4692-a3e4-3f8231bc82bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_motion_track(input_video,output_video):\n",
    "\n",
    "    # Create a VideoCapture object\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "    # Get the original video's width and height\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Get the frame rate\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    print(width)\n",
    "    print(height)\n",
    "    print(fps)\n",
    "\n",
    "    # Define the codec and create a VideoWriter object\n",
    "    # Set the video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    #fourcc = cv2.VideoWriter_fourcc(*'MP4V') \n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (width, height))  # You may need to adjust the resolution (640x480 in this example)\n",
    "\n",
    "    # Initialize the pose detection module\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Read a frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # Resize the frame for portrait video\n",
    "            #frame = cv2.resize(frame, (350, 600))\n",
    "\n",
    "            # Convert to RGB\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Process the frame for pose detection\n",
    "            pose_results = pose.process(frame_rgb)\n",
    "\n",
    "            # Draw skeleton on the frame\n",
    "            #mp_drawing.draw_landmarks(frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "            #Draw skeleton on the frame excluding eyes\n",
    "            mp_drawing.draw_landmarks(frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                      landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2),\n",
    "                                      connection_drawing_spec=mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2))\n",
    "\n",
    "            # Extract and print name, x, y coordinates of each landmark along with timestamp\n",
    "            if pose_results.pose_landmarks:\n",
    "                timestamp = cap.get(cv2.CAP_PROP_POS_MSEC)  # Get the current timestamp in milliseconds\n",
    "                for idx, landmark in enumerate(pose_results.pose_landmarks.landmark):\n",
    "                    landmark_name = mp_pose.PoseLandmark(idx).name\n",
    "                    x = int(landmark.x * width)\n",
    "                    y = int(landmark.y * height)\n",
    "                    #print(f\"Timestamp: {timestamp} ms, Landmark {landmark_name}: ({x}, {y})\")\n",
    "\n",
    "                 # Add timestamp as text to the frame\n",
    "                cv2.putText(frame, f'Timestamp: {int(timestamp)} ms', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Write the frame to the output video file\n",
    "            out.write(frame)\n",
    "\n",
    "            # Display the frame\n",
    "            cv2.imshow('Output', frame)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            break\n",
    "\n",
    "        # Break the loop if 'q' key is pressed\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the VideoCapture and VideoWriter objects\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53422574-231b-4e9a-893c-07429a92ca2d",
   "metadata": {},
   "source": [
    "# RUN JOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e063615-c733-44b0-8850-de76ab858f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video shortened successfully to 0.8 seconds.\n",
      "Video shortened successfully to 0 seconds.\n",
      "1080\n",
      "1920\n",
      "30.0\n",
      "1080\n",
      "1920\n",
      "30.0\n",
      "Videos combined side by side successfully using all CPUs.\n",
      "Video converted to animated GIF successfully.\n"
     ]
    }
   ],
   "source": [
    "input_video = fileList[1]\n",
    "output_video = 'shortened_video-A.mov'\n",
    "shortened_duration = .8\n",
    "trim_video_from_beg(ffmpeg_path,input_video,output_video,shortened_duration)\n",
    "\n",
    "input_video = fileList[0]\n",
    "output_video = 'shortened_video-B.mov'\n",
    "shortened_duration = 0\n",
    "trim_video_from_beg(ffmpeg_path,input_video,output_video,shortened_duration)\n",
    "\n",
    "add_motion_track('shortened_video-A.mov','motionA.avi')\n",
    "add_motion_track('shortened_video-B.mov','motionB.avi')\n",
    "\n",
    "# Output video file (combined side by side)\n",
    "output_video = 'combined_videoC.mp4'\n",
    "input_video1 = 'motionB.avi'\n",
    "input_video2 = 'motionA.avi'\n",
    "merge_two_videos_sbys(ffmpeg_path,input_video1,input_video2,output_video) \n",
    "\n",
    "make_gif(output_video,\"image.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1bee69f-3e66-456b-af7f-6802dc30ca0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_video = fileList[3]\n",
    "output_video = 'shortened_video-A.mov'\n",
    "shortened_duration = 0\n",
    "trim_video_from_beg(ffmpeg_path,input_video,output_video,shortened_duration)\n",
    "\n",
    "input_video = fileList[2]\n",
    "output_video = 'shortened_video-B.mov'\n",
    "shortened_duration = 4.2\n",
    "trim_video_from_beg(ffmpeg_path,input_video,output_video,shortened_duration)\n",
    "\n",
    "add_motion_track('shortened_video-A.mov','motionA.avi')\n",
    "add_motion_track('shortened_video-B.mov','motionB.avi')\n",
    "\n",
    "# Output video file (combined side by side)\n",
    "output_video = 'combined_videoC.mp4'\n",
    "input_video1 = 'motionB.avi'\n",
    "input_video2 = 'motionA.avi'\n",
    "merge_two_videos_sbys(ffmpeg_path,input_video1,input_video2,output_video) \n",
    "\n",
    "make_gif(output_video,\"image1.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681269a3-700e-42c9-894d-b2d06b976228",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_gif(output_video,\"image1.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fafc9b-fd30-4cf1-adc3-0b63cc419454",
   "metadata": {},
   "source": [
    "# REDUCE VIDEO SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59756f5a-00e6-4c43-afbf-8d0665dba5e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_video = \"combined_videoC.mp4\"\n",
    "output_video = \"compressed_video.mp4\"\n",
    "\n",
    "# FFmpeg command to compress the video with H.265 codec\n",
    "ffmpeg_command = [\n",
    "    ffmpeg_path,\n",
    "    \"-i\", input_video,\n",
    "    \"-c:v\", \"libx265\",\n",
    "    output_video\n",
    "]\n",
    "\n",
    "# Execute the FFmpeg command\n",
    "subprocess.run(ffmpeg_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbdc2e0-87a3-4eac-867a-15a7108ac9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7626f0-a067-4e47-aae9-1a97b07ce35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f711a84c-d50a-424a-969a-a47082140c47",
   "metadata": {},
   "source": [
    "# CAPTURE USB CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba3069f-9181-40fb-8951-e9418cb51303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Change the argument in VideoCapture to the index of your USB camera\n",
    "cap = cv2.VideoCapture(1)  # Change the index to match your USB camera\n",
    "\n",
    "# Set the video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))  # You may need to adjust the resolution (640x480 in this example)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # read frame\n",
    "    _, frame = cap.read()\n",
    "    try:\n",
    "        # resize the frame for portrait video\n",
    "        # frame = cv2.resize(frame, (350, 600))\n",
    "        # convert to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # process the frame for pose detection\n",
    "        pose_results = pose.process(frame_rgb)\n",
    "        # print(pose_results.pose_landmarks)\n",
    "        \n",
    "        # draw skeleton on the frame\n",
    "        mp_drawing.draw_landmarks(frame, pose_results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "        # Write the frame to the video\n",
    "        out.write(frame)\n",
    "        \n",
    "        # display the frame\n",
    "        cv2.imshow('Output', frame)\n",
    "    except:\n",
    "        break\n",
    "        \n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()  # Release the video writer\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32a5bd-4772-43e2-a8d0-05f632353635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
