{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72148f50-8a37-41c6-9f72-621069a299b9",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a90da32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !apt-get update\n",
    "# !apt install libgl1-mesa-glx\n",
    "# !pip install --upgrade jupyter ipywidgets\n",
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !jupyter contrib nbextension install --user\n",
    "# !jupyter nbextension enable toc2/main\n",
    "# !pip install wandb timm ipywidgets albumentations\n",
    "# !pip install -U albumentations[imgaug]\n",
    "# !pip install matplotlib\n",
    "# !pip install scikit-learn\n",
    "# !pip install albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce7f3a5-866a-4ff7-8af6-2aa885cde814",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e75eb3",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "import json\n",
    "import timm\n",
    "import wandb\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torch.distributed as dist\n",
    "from torch.cuda.amp import autocast,GradScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import timm\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from timm.scheduler.step_lr import StepLRScheduler\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import timm\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from timm.scheduler.plateau_lr import PlateauLRScheduler\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix,mean_squared_error,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bba939",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ea148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAINDIR=\"../datasets/FER2013/train\"\n",
    "VALDIR=\"../datasets/FER2013/test\"\n",
    "IMAGES = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a469d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes_train = os.listdir(TRAINDIR)\n",
    "classes_valid = os.listdir(VALDIR)\n",
    "\n",
    "print(f'Train Classes - {classes_train}')\n",
    "print(f'Validation Classes - {classes_valid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a604501",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = TRAINDIR\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.ToTensor(),])\n",
    "\n",
    "def get_random_images(num):\n",
    "    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "    classes = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n",
    "    images, labels = next(iter(loader))  # Get the first batch of data   \n",
    "    return images, labels, classes\n",
    "        \n",
    "counter = 0\n",
    "while counter < 5:\n",
    "    to_pil = transforms.ToPILImage()\n",
    "    images, labels, classes = get_random_images(10)\n",
    "    fig=plt.figure(figsize=(17,17))\n",
    "    for ii in range(len(images)):\n",
    "        image = to_pil(images[ii])\n",
    "        sub = fig.add_subplot(1, len(images), ii+1)\n",
    "        res = int(labels[ii])\n",
    "        sub.set_title(classes[res] )\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c7df72-26df-46bc-8335-bc102b818e81",
   "metadata": {},
   "source": [
    "## Load AWS & WANDB API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402b1dc-386f-4e03-8293-05133048f6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('config.json') as config_f:\n",
    "    data = json.load(config_f)\n",
    "\n",
    "aws_access_key_id = data['aws_access_key_id']\n",
    "aws_secret_access_key = data['aws_secret_access_key']\n",
    "region_name = data['region_name']\n",
    "WANDB_API_KEY = data['WANDB_API_KEY']\n",
    "phone = data['phone']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7343d8e2",
   "metadata": {},
   "source": [
    "# MODEL TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef554c8",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#S3 Keys\n",
    "ACCESS_KEY = aws_access_key_id\n",
    "SECRET_KEY = aws_secret_access_key\n",
    "\n",
    "GPU=0\n",
    "SEED=1\n",
    "ARCH = 'resnet50'\n",
    "EPOCHS = 100\n",
    "START_EPOCH = 0\n",
    "LR = 0.01\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 10\n",
    "TRAIN_BATCH= 550\n",
    "imagesize = 244\n",
    "VAL_BATCH=TRAIN_BATCH\n",
    "WORKERS=4\n",
    "TRAINDIR=\"../datasets/FER2013/train\"\n",
    "VALDIR=\"../datasets/FER2013/test\"\n",
    "\n",
    "use_autocast = True\n",
    "LR_EPOCH_DROP = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c335661",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = False\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b15332d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY\n",
    "wandb.login()\n",
    "run = wandb.init(project=\"EmotionDetection\",config={\"epochs\": EPOCHS, \"batch_size\": TRAIN_BATCH, \"momentum\": MOMENTUM, \"WEIGHT_DECAY\": WEIGHT_DECAY, \"arch\": ARCH})\n",
    "\n",
    "wandb_run_name = wandb.run.name\n",
    "wandb_run_id = wandb.run.id\n",
    "\n",
    "config = wandb.config\n",
    "config.learning_rate = LR\n",
    "config.LR_EPOCH_DROP = LR_EPOCH_DROP\n",
    "config.use_autocast = use_autocast\n",
    "\n",
    "wandb.run.log_code(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669a06d-ffb0-4bf5-8f96-8c4993558e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd32d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_to_aws(local_file, bucket, s3_file):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=ACCESS_KEY,\n",
    "                      aws_secret_access_key=SECRET_KEY)\n",
    "    try:\n",
    "        s3.upload_file(local_file, bucket, s3_file)\n",
    "        print(\"Upload Successful\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found\")\n",
    "        return False\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False\n",
    "\n",
    "def download_from_aws(s3_file, bucket):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=ACCESS_KEY,\n",
    "                      aws_secret_access_key=SECRET_KEY)\n",
    "    try:\n",
    "        s3.download_file(bucket, s3_file, s3_file)\n",
    "        print(\"Download Successful\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found\")\n",
    "        return False\n",
    "    except NoCredentialsError:\n",
    "        print(\"Credentials not available\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e8f2d",
   "metadata": {
    "id": "4e65743f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # Grad Scaler\n",
    "    scaler = GradScaler()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with autocast():\n",
    "          output = model(images)\n",
    "          loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        #wandb.log({\"Loss/train\": loss, 'acc1/train': top1.avg, 'acc5/train': top5.avg})\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86dc93",
   "metadata": {
    "id": "ab30a1a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "\n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4902b7",
   "metadata": {
    "id": "afa7d9fd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename_in):\n",
    "    torch.save(state, filename_in)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename_in, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e2bc6",
   "metadata": {
    "id": "8c5f0ab4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff7630",
   "metadata": {
    "id": "ce30c86a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962ccd4b",
   "metadata": {
    "id": "7504ce7a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // LR_EPOCH_DROP))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2786cc",
   "metadata": {
    "id": "0d659923",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d91d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    #transforms.RandomAffine(degrees=3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomRotation(degrees=(0, 5)),\n",
    "    #transforms.RandomPerspective(distortion_scale=0.8, p=1.0),\n",
    "    #transforms.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.9, 0.99)),\n",
    "    #transforms.RandomEqualize(),\n",
    "    #transforms.RandomAutocontrast(),\n",
    "    #transforms.RandomSolarize(threshold=192.0),\n",
    "    #transforms.RandomPosterize(bits=2),\n",
    "    #transforms.RandomInvert(),\n",
    "    #transforms.RandomAdjustSharpness(sharpness_factor=2),\n",
    "    #transforms.Resize(imagesize),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d4da6",
   "metadata": {
    "id": "e5275a69",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2d9eb",
   "metadata": {
    "id": "854ca1ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    #transforms.Resize(imagesize),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023b2b6",
   "metadata": {
    "id": "abfa5fb6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44888f7",
   "metadata": {
    "id": "07a0bdf4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d5fdd3",
   "metadata": {
    "id": "192ae835",
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=True,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97aa04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_loader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681df5f",
   "metadata": {
    "id": "94059b7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 7\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device\",str(device))\n",
    "\n",
    "#model = timm.create_model(ARCH, pretrained = True, num_classes=NUM_CLASSES,drop_rate=0.8)\n",
    "model = timm.create_model(ARCH, pretrained = True, num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Scheduler and Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = timm.scheduler.StepLRScheduler(optimizer, decay_t = LR_EPOCH_DROP, decay_rate=.5)\n",
    "\n",
    "n_steps = len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d6667-27c4-442d-88d1-e5ad19013de0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757f915",
   "metadata": {
    "id": "ceb95e07",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "best_acc1 = 0\n",
    "best_epoch = 0\n",
    "lrls = []\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    #adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    PATH = \"M1_\" +str(epoch) + \"_acc1_\" +str(acc1) + \"_\" + ARCH + \".tar\" \n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best,PATH)\n",
    "    \n",
    "    scheduler.step(epoch + 1)\n",
    "    lr_rate =  get_lr(optimizer)\n",
    "    lrls.append(lr_rate)          \n",
    "    print('lr: ' + str(lr_rate))\n",
    "    wandb.log({'lr':lr_rate, 'epoch':epoch,\"best_acc1/val\": best_acc1,\"best_epoch\": best_epoch})    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa166ff7",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8c324f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97592fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.Grayscale(num_output_channels=3),\n",
    "                                      transforms.ToTensor(),                                      \n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d21d7dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        image_tensor = test_transforms(image).float()\n",
    "        image_tensor = image_tensor.unsqueeze_(0)\n",
    "        input = Variable(image_tensor)\n",
    "        input = input.to(device)\n",
    "        output = model(input)\n",
    "        index = output.data.cpu().numpy().argmax()\n",
    "       \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4fc7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_random_images(num):\n",
    "    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "    classes = data.classes\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n",
    "    images, labels = next(iter(loader))  # Get the first batch of data   \n",
    "    return images, labels, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35bdea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir=\"../datasets/FER2013/test\"\n",
    "to_pil = transforms.ToPILImage()\n",
    "images, labels, classes = get_random_images(15)\n",
    "fig=plt.figure(figsize=(15,15))\n",
    "\n",
    "counter = 0\n",
    "while counter < 5:\n",
    "    to_pil = transforms.ToPILImage()\n",
    "    images, labels, classes = get_random_images(10)\n",
    "    fig=plt.figure(figsize=(17,17))\n",
    "    for ii in range(len(images)):\n",
    "        image = to_pil(images[ii])\n",
    "        index = predict_image(image)\n",
    "        sub = fig.add_subplot(1, len(images), ii+1)\n",
    "        res = int(labels[ii])\n",
    "        label_class = int(labels[ii])\n",
    "        sub.set_title(str(classes[index]) + \":\" + classes[label_class])\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image)\n",
    "    plt.show()\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343e1b1",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6efde7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actual = []\n",
    "predicted = []\n",
    "\n",
    "to_pil = transforms.ToPILImage()\n",
    "images, labels, classes = get_random_images(3000)\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    index = predict_image(image)\n",
    "    res = int(labels[ii])\n",
    "    label_class = int(labels[ii])\n",
    "    actual.append(classes[label_class])\n",
    "    predicted.append(str(classes[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9700adba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(actual[20])\n",
    "print(predicted[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e35aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cdb2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4),frameon =False, dpi=200)  \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.1f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc16eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "class_names = classes\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,title='Normalized confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(actual, predicted, target_names=class_names))\n",
    "\n",
    "print(accuracy_score(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0219d2-f1b2-4985-a072-cbd5afb5ae05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
